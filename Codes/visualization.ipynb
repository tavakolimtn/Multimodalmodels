{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb62a1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# read data\n",
    "data_new=pd.read_csv(\"data.csv\")\n",
    "\n",
    "data=data_new.loc[:,[\"cleantext\", \"RATING\"]]\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "data_main=data\n",
    "lbl_first=data_main[\"RATING\"].values\n",
    "lbl_final=lbl_first.copy()\n",
    "dict_trans_calss={1:[1,2,3,4,5],\n",
    "                  2:[6],\n",
    "                  3:[7],\n",
    "                  4:[8],\n",
    "                  5:[9],\n",
    "                 6:[10,11,12],\n",
    "                  7:[13,14,15],\n",
    "                  8:[16,17,18,19,20,21,22]\n",
    "                  }\n",
    "for calss_main_idx in dict_trans_calss:\n",
    "  lst_class=dict_trans_calss[calss_main_idx]\n",
    "  for idx, item in enumerate(lst_class):\n",
    "    lbl_final = np.where(lbl_first == item, calss_main_idx, lbl_final)\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8,6))\n",
    "# plot by pandas for value count for each class\n",
    "data_main[\"RATING\"].value_counts().plot(kind=\"bar\")\n",
    "plt.xlabel(\"Rating class name\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "unique, counts = np.unique(lbl_final, return_counts=True)\n",
    "lst_class=[ \"class \"+ str(item) for item in unique]\n",
    "plt.figure(figsize=(8,8))\n",
    "palette_color = sns.color_palette('muted')\n",
    "plt.pie(counts,\n",
    "        labels=lst_class,\n",
    "        colors=palette_color, \n",
    "        autopct='%.0f%%',\n",
    "        textprops={'fontsize': 14})\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "lbl_final_rest=lbl_final.copy()\n",
    "uni_class=np.unique(lbl_final)\n",
    "for idx,item in enumerate(uni_class):\n",
    "  lbl_final_rest=np.where(lbl_final == item, idx, lbl_final_rest)\n",
    "unique, counts = np.unique(lbl_final_rest, return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)\n",
    "\n",
    "data_pre=data_main.copy()\n",
    "\n",
    "\n",
    "\n",
    "data_token=data_pre[\"cleantext\"].values\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "plt.figure(figsize=(8,8))\n",
    "text = data_token\n",
    "wordcloud = WordCloud().generate(str(text))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "MAX_NB_WORDS=500000\n",
    "m1=[]\n",
    "m2=[]\n",
    "for i in range(1,9):\n",
    "    data1=data_pre[data_pre.RATING==i]\n",
    "    data_token=data1[\"cleantext\"].values\n",
    "    tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "    tokenizer.fit_on_texts(data_token)\n",
    "    data_seq = tokenizer.texts_to_sequences(data_token)\n",
    "    #vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index\n",
    "    #print(data_token[-1])\n",
    "    #print(data_seq[-1])\n",
    "    frq_words=[len(item) for item in data_seq]\n",
    "    m1.append(np.mean(frq_words))\n",
    "    m2.append(i)\n",
    "\n",
    "\n",
    "data_plot=pd.DataFrame(columns=[\"Number of Words\", \"Rating Class\"])\n",
    "\n",
    "data_plot[\"Number of Words\"]=m1\n",
    "data_plot[\"Rating Class\"]=m2\n",
    "\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(data=data_plot,x=\"Rating Class\",y=\"Number of Words\",color = 'lightblue')\n",
    "plt.xlabel=(\"Frequency\")\n",
    "plt.ylabel=(\"Words\")\n",
    "#plt.xticks(rotation=10)\n",
    "plt.show()\n",
    "#plt.figure(figsize=(16,8))\n",
    "#plt.bar(x=range(len(data_seq)),height=frq_words)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.bar(x=range(len(data_seq)),height=frq_words)\n",
    "plt.xlabel(\"Document\")\n",
    "plt.ylabel(\"Frequency of the words\")\n",
    "plt.ylim(0,17500)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "max=8000\n",
    "f=frq_words\n",
    "for i in range(len(frq_words)):\n",
    "    if frq_words[i]>max:\n",
    "        f[i]=max\n",
    "\n",
    "\n",
    "\n",
    "f=[i for i in f if i<50]\n",
    "\n",
    "\n",
    "ff=f\n",
    "min=500\n",
    "f=frq_words\n",
    "for i in range(len(f)):\n",
    "    if f[i]<min:\n",
    "        ff[i]=min\n",
    "\n",
    "\n",
    "# In[62]:\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import percentile\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "plt.figure(figsize=(16,8))\n",
    "sns.histplot(data=f,bins=20) \n",
    "plt.xlabel(\"Number of the words in the documents\")\n",
    "#plt.ylabel(\"Frequency of the words\")\n",
    "plt.xlim(50,8300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf7aade",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ngram\n",
    "data[\"Group\"]=data.RATING<10\n",
    "\n",
    "len(data_group1)\n",
    "\n",
    "len(data_group2)\n",
    "\n",
    "3000/13050\n",
    "\n",
    "\"\"\"# **2- split group**\"\"\"\n",
    "\n",
    "data_group1=data[data[\"Group\"]==True]\n",
    "data_group2=data[data[\"Group\"]==False]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "plt.figure(figsize=(8,8))\n",
    "text = data_group1.values\n",
    "wordcloud = WordCloud().generate(str(text))\n",
    "wordcloud = WordCloud(stopwords=['thats','would','think']).generate(str(text))\n",
    "\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "plt.figure(figsize=(8,8))\n",
    "text = data_group2.values\n",
    "wordcloud = WordCloud(stopwords=['thats','would','think']).generate(str(text))\n",
    "\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "plt.figure(figsize=(8,8))\n",
    "text = data_group2.values\n",
    "wordcloud = WordCloud(stopwords=['thats','would','think']).generate(str(text))\n",
    "\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "\"\"\"# **3- get ngram**\n",
    "\n",
    "n=1\n",
    "\"\"\"\n",
    "\n",
    "max_feature=10\n",
    "plus_name=100\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "ngram_vec= CountVectorizer( ngram_range=(1, 1),max_features=max_feature+plus_name)\n",
    "fea_count_groub1=ngram_vec.fit_transform(data_group1['cleantext'].values).toarray()\n",
    "count_group1=np.sum(fea_count_groub1,axis=0).tolist()\n",
    "name_group1=ngram_vec.get_feature_names_out().tolist()\n",
    "\n",
    "name_group11=name_group1\n",
    "count_group11=count_group1\n",
    "count_group11, name_group11 = (list(t) for t in zip(*sorted(zip(count_group11, name_group11),reverse=True)))\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "ngram_vec= CountVectorizer(ngram_range=(1, 1),max_features=max_feature+plus_name)\n",
    "fea_count_groub2=ngram_vec.fit_transform(data_group2['cleantext'].values).toarray()\n",
    "count_group2=np.sum(fea_count_groub2,axis=0).tolist()\n",
    "name_group2=ngram_vec.get_feature_names_out().tolist()\n",
    "\n",
    "name_group22=name_group2\n",
    "count_group22=count_group2\n",
    "count_group22, name_group22 = (list(t) for t in zip(*sorted(zip(count_group22, name_group22),reverse=True)))\n",
    "\n",
    "list_ex=[\"thanks\",\"thats\",\"theres\",\"two\",\"weve\",\"yes\",\"youre\",\"seeing\",\"going\",\"lot\",\"im\",\"inc\",\"increased\"]\n",
    "count_new_group2=[]\n",
    "name_new_group2=[]\n",
    "for idx, item in enumerate(name_group2):\n",
    "  if(item  not in name_group11[0:50] and item  not in list_ex ):\n",
    "    print(item)\n",
    "    name_new_group2.append(item)\n",
    "    count_new_group2.append(count_group2[idx])\n",
    "\n",
    "count_new_group22, name_new_group22 = (list(t) for t in zip(*sorted(zip(count_new_group2, name_new_group2),reverse=True)))\n",
    "name_new_group22\n",
    "\n",
    "count_new_group1=[]\n",
    "name_new_group1=[]\n",
    "for idx, item in enumerate(name_group1):\n",
    "  if(item  not in name_group22[0:30] and item  not in list_ex and item  not in name_new_group22 ):\n",
    "    #print(item)\n",
    "    name_new_group1.append(item)\n",
    "    count_new_group1.append(count_group2[idx])\n",
    "\n",
    "count_new_group11, name_new_group11 = (list(t) for t in zip(*sorted(zip(count_new_group1, name_new_group1),reverse=True)))\n",
    "name_new_group11\n",
    "\n",
    "max_feature=20\n",
    "count_new_group1=count_new_group11[0:max_feature]\n",
    "name_new_group1=name_new_group11[0:max_feature]\n",
    "\n",
    "data_plot=pd.DataFrame(columns=[\"Group1 Words\", \"Group1 Count\",\n",
    "                                \"Group2 Words\", \"Group2 Count\",\n",
    "                                ])\n",
    "l=20\n",
    "data_plot[\"Group1 Words\"]=name_new_group11[:l]\n",
    "data_plot[\"Group1 Count\"]=count_new_group11[:l]\n",
    "data_plot[\"Group2 Words\"]=name_new_group22[:l]\n",
    "data_plot[\"Group2 Count\"]=count_new_group22[:l]\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis='both', which='major', labelsize=24)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=16)\n",
    "\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(10,12))\n",
    "sns.barplot(data=data_plot,y=\"Group1 Words\",x=\"Group1 Count\",orientation='horizontal')\n",
    "plt.xlabel=(\"Frequency\")\n",
    "plt.ylabel=(\"Words\")\n",
    "#plt.xticks(rotation=10)\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis='y', which='major', labelsize=20)\n",
    "#ax.tick_params(axis='y', which='minor', labelsize=20)\n",
    "plt.show()\n",
    "\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(10,12))\n",
    "sns.barplot(data=data_plot,y=\"Group2 Words\",x=\"Group2 Count\",orientation='horizontal')\n",
    "#plt.xticks(rotation=10)\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis='y', which='major', labelsize=20)\n",
    "#ax.tick_params(axis='y', which='minor', labelsize=20)\n",
    "plt.show()\n",
    "plt.show()\n",
    "\n",
    "\"\"\"# **n**=2\"\"\"\n",
    "\n",
    "max_feature=10\n",
    "plus_name=50\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "ngram_vec= CountVectorizer( ngram_range=(2, 2),max_features=max_feature+plus_name)\n",
    "fea_count_groub1=ngram_vec.fit_transform(data_group1['cleantext'].values).toarray()\n",
    "count_group1=np.sum(fea_count_groub1,axis=0).tolist()\n",
    "name_group1=ngram_vec.get_feature_names_out().tolist()\n",
    "\n",
    "name_group11=name_group1\n",
    "count_group11=count_group1\n",
    "count_group11, name_group11 = (list(t) for t in zip(*sorted(zip(count_group11, name_group11),reverse=True)))\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "ngram_vec= CountVectorizer(ngram_range=(2, 2),max_features=max_feature+plus_name)\n",
    "fea_count_groub2=ngram_vec.fit_transform(data_group2['cleantext'].values).toarray()\n",
    "count_group2=np.sum(fea_count_groub2,axis=0).tolist()\n",
    "name_group2=ngram_vec.get_feature_names_out().tolist()\n",
    "\n",
    "name_group22=name_group2\n",
    "count_group22=count_group2\n",
    "count_group22, name_group22 = (list(t) for t in zip(*sorted(zip(count_group22, name_group22),reverse=True)))\n",
    "name_group22\n",
    "\n",
    "list_ex=[\"good morning\",\"adjusted ebitda\",\"forwardlooking statements\",\"goldman sachs\",\"questionandanswer session\",\"think thats\",\"million million\",\"weve got\",\"weve seen\"]\n",
    "count_new_group2=[]\n",
    "name_new_group2=[]\n",
    "for idx, item in enumerate(name_group2):\n",
    "  if(item  not in name_group11[0:30] and item  not in list_ex ):\n",
    "    print(item)\n",
    "    name_new_group2.append(item)\n",
    "    count_new_group2.append(count_group2[idx])\n",
    "\n",
    "count_new_group22, name_new_group22 = (list(t) for t in zip(*sorted(zip(count_new_group2, name_new_group2),reverse=True)))\n",
    "name_new_group22\n",
    "\n",
    "count_new_group1=[]\n",
    "name_new_group1=[]\n",
    "for idx, item in enumerate(name_group1):\n",
    "  if(item  not in list_ex and item not in name_group22[0:10] and item not in name_new_group22):\n",
    "    #print(item)\n",
    "    name_new_group1.append(item)\n",
    "    count_new_group1.append(count_group2[idx])\n",
    "count_new_group11, name_new_group11 = (list(t) for t in zip(*sorted(zip(count_new_group1, name_new_group1),reverse=True)))\n",
    "name_new_group11\n",
    "\n",
    "len(name_new_group22)\n",
    "\n",
    "max_feature=20\n",
    "count_new_group11=count_new_group11[0:max_feature]\n",
    "name_new_group11=name_new_group11[0:max_feature]\n",
    "\n",
    "count_new_group22=count_new_group22[0:max_feature]\n",
    "name_new_group22=name_new_group22[0:max_feature]\n",
    "\n",
    "data_plot=pd.DataFrame(columns=[\"Group1 Words\", \"Group1 Count\",\n",
    "                                \"Group2 Words\", \"Group2 Count\",\n",
    "                                ])\n",
    "data_plot[\"Group1 Words\"]=name_new_group11\n",
    "data_plot[\"Group1 Count\"]=count_new_group11\n",
    "data_plot[\"Group2 Words\"]=name_new_group22\n",
    "data_plot[\"Group2 Count\"]=count_new_group22\n",
    "\n",
    "data_plot\n",
    "\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(10,12))\n",
    "sns.barplot(data=data_plot,y=\"Group2 Words\",x=\"Group2 Count\",orientation='horizontal')\n",
    "#plt.xticks(rotation=20)\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis='y', which='major', labelsize=20)\n",
    "ax.tick_params(axis='y', which='minor', labelsize=20)\n",
    "plt.show()\n",
    "plt.show()\n",
    "\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(10,12))\n",
    "sns.barplot(data=data_plot,y=\"Group2 Words\",x=\"Group2 Count\",orientation='horizontal')\n",
    "#plt.xticks(rotation=20)\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis='y', which='major', labelsize=20)\n",
    "#ax.tick_params(axis='y', which='minor', labelsize=20)\n",
    "plt.show()\n",
    "plt.show()\n",
    "\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(10,12))\n",
    "sns.barplot(data=data_plot,y=\"Group1 Words\",x=\"Group1 Count\",orientation='horizontal')\n",
    "#plt.xticks(rotation=20)\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis='y', which='major', labelsize=20)\n",
    "#ax.tick_params(axis='y', which='minor', labelsize=20)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(10,12))\n",
    "sns.barplot(data=data_plot,y=\"Group1 Words\",x=\"Group1 Count\",orientation='horizontal')\n",
    "#plt.xticks(rotation=20)\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis='y', which='major', labelsize=20)\n",
    "#ax.tick_params(axis='y', which='minor', labelsize=20)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
